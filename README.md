# ðŸ§  AI Project - Comparing Machine Learning Models

## ðŸŽ“ Context
This project was carried out as part of the **Bachelorâ€™s in Mathematics & Computer Science** (University of Strasbourg), course **Artificial Intelligence**.  
The goal is to design, train, analyze, and compare two families of machine learning models:  
- **Decision Trees**  
- **Artificial Neural Networks**

---

## ðŸ“‚ Repository Structure
- `src/` â†’ Python scripts  
- `notebooks/` â†’ clean and organized Jupyter notebooks  
- `report.pdf` â†’ written report (answers to project questions)  
- `synthetique.csv` â†’ provided dataset  
- `predictions.zip` â†’ pre-computed predictions (provided for analysis if needed)  
- `auto_evaluation.pdf` â†’ completed self-evaluation form  

---

## âœ… Learning Objectives
- Prepare and analyze a synthetic dataset  
- Implement decision trees and artificial neural networks  
- Apply techniques such as:  
  - **Quartile-based partitioning** (for decision trees)  
  - **Mini-batch learning** and **early stopping** (for neural networks)  
- Compute and interpret classic evaluation metrics:  
  - Accuracy  
  - Precision  
  - Recall  
  - F1-score  
- Compare models and argue which one is better  

---

## ðŸ”Ž Project Workflow
### 1. Data Preparation
- Split dataset into **80% training / 20% testing**  
- Encoding and normalization if required  
- Check linear separability of the data  

### 2. Model Implementation
#### ðŸŒ³ Decision Trees
- Partitioning with **quartiles**  
- Training trees with depths from 3 to 8  
- Keep the **two best-performing models**

#### ðŸ§  Neural Networks
- Validation set (15% of training) for **early stopping** (patience=4)  
- Training with mini-batches of size 4  
- Tested architectures:  
  - Activation **tanh**: (10,8,6), (10,8,4), (6,4)  
  - Activation **relu**: (10,8,6), (10,8,4), (6,4)  
- Keep the **two best-performing models per activation function**

### 3. Model Analysis
- Manually compute metrics (without external libraries):  
  - Accur
